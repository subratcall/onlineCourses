{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.GAN import GAN\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from utils.loaders import load_safari, load_safari_npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0620 12:02:59.459117 140356798768960 deprecation_wrapper.py:119] From /home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0620 12:02:59.473270 140356798768960 deprecation_wrapper.py:119] From /home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0620 12:02:59.485563 140356798768960 deprecation_wrapper.py:119] From /home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0620 12:02:59.487335 140356798768960 deprecation_wrapper.py:119] From /home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0620 12:02:59.497436 140356798768960 deprecation.py:506] From /home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0620 12:02:59.695515 140356798768960 deprecation_wrapper.py:119] From /home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0620 12:02:59.717719 140356798768960 deprecation_wrapper.py:119] From /home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0620 12:03:00.311888 140356798768960 deprecation_wrapper.py:119] From /home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0620 12:03:00.545593 140356798768960 deprecation_wrapper.py:119] From /home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0620 12:03:00.553889 140356798768960 deprecation.py:323] From /home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(input_dim=(28,28,1),\n",
    "          discriminator_conv_filters=[64,64,128,128],\n",
    "          discriminator_conv_kernel_size=[5,5,5,5],\n",
    "          discriminator_conv_strides=[2,2,2,1],\n",
    "          discriminator_batch_norm_momentum=None,\n",
    "          discriminator_activation='relu',\n",
    "          discriminator_dropout_rate=0.4,\n",
    "          discriminator_learning_rate=0.0008,\n",
    "          generator_initial_dense_layer_size=(7,7,64),\n",
    "          generator_upsample=[2,2,1,1],\n",
    "          generator_conv_filters=[128,64,64,1],\n",
    "          generator_conv_kernel_size=[5,5,5,5],\n",
    "          generator_conv_strides=[1,1,1,1],\n",
    "          generator_batch_norm_momentum=0.9,\n",
    "          generator_activation='relu',\n",
    "          generator_dropout_rate=None,\n",
    "          generator_learning_rate=0.0004,\n",
    "          optimiser='rmsprop',\n",
    "          z_dim=100\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'gan'\n",
    "RUN_ID = '0001'\n",
    "DATA_NAME = 'full_numpy_bitmap_lightning.npy'\n",
    "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'save' #'load' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'save':\n",
    "    gan.save(RUN_FOLDER)\n",
    "else:\n",
    "    gan.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_0 (Conv2D (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_1 (Conv2D (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_2 (Conv2D (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_conv_3 (Conv2D (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 720,833\n",
      "Trainable params: 720,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_0 (Conv2D)    (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_conv_1 (Conv2D)    (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_2 (Conv2DTran (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_conv_3 (Conv2DTran (None, 28, 28, 1)         1601      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 844,161\n",
      "Trainable params: 837,377\n",
      "Non-trainable params: 6,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = load_safari_npy(DATA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5000\n",
    "PRINT_EVERY_N_BATCHES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: (1.268)(R 1.802, F 0.734)] [D acc: (0.117)(0.234, 0.000)] [G loss: 0.580] [G acc: 1.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bram/miniconda3/envs/generative/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: (0.486)(R 0.000, F 0.972)] [D acc: (0.500)(1.000, 0.000)] [G loss: 0.689] [G acc: 1.000]\n",
      "2 [D loss: (0.347)(R 0.000, F 0.694)] [D acc: (0.617)(1.000, 0.234)] [G loss: 0.685] [G acc: 1.000]\n",
      "3 [D loss: (0.346)(R 0.000, F 0.692)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.680] [G acc: 1.000]\n",
      "4 [D loss: (0.346)(R 0.000, F 0.692)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.673] [G acc: 1.000]\n",
      "5 [D loss: (0.346)(R 0.000, F 0.691)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.667] [G acc: 1.000]\n",
      "6 [D loss: (0.345)(R 0.000, F 0.691)] [D acc: (0.996)(1.000, 0.992)] [G loss: 0.661] [G acc: 1.000]\n",
      "7 [D loss: (0.345)(R 0.000, F 0.690)] [D acc: (0.988)(1.000, 0.977)] [G loss: 0.658] [G acc: 1.000]\n",
      "8 [D loss: (0.345)(R 0.000, F 0.691)] [D acc: (0.945)(1.000, 0.891)] [G loss: 0.658] [G acc: 1.000]\n",
      "9 [D loss: (0.346)(R 0.000, F 0.692)] [D acc: (0.875)(1.000, 0.750)] [G loss: 0.667] [G acc: 0.969]\n",
      "10 [D loss: (0.346)(R 0.000, F 0.693)] [D acc: (0.891)(1.000, 0.781)] [G loss: 0.679] [G acc: 0.867]\n",
      "11 [D loss: (0.345)(R 0.000, F 0.691)] [D acc: (0.902)(1.000, 0.805)] [G loss: 0.688] [G acc: 0.758]\n",
      "12 [D loss: (0.345)(R 0.000, F 0.689)] [D acc: (0.930)(1.000, 0.859)] [G loss: 0.695] [G acc: 0.234]\n",
      "13 [D loss: (0.344)(R 0.000, F 0.688)] [D acc: (0.965)(1.000, 0.930)] [G loss: 0.699] [G acc: 0.000]\n",
      "14 [D loss: (0.343)(R 0.000, F 0.686)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.700] [G acc: 0.000]\n",
      "15 [D loss: (0.343)(R 0.000, F 0.685)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.701] [G acc: 0.000]\n",
      "16 [D loss: (0.342)(R 0.000, F 0.685)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.702] [G acc: 0.000]\n",
      "17 [D loss: (0.342)(R 0.000, F 0.684)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.703] [G acc: 0.000]\n",
      "18 [D loss: (0.342)(R 0.000, F 0.684)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.703] [G acc: 0.000]\n",
      "19 [D loss: (0.341)(R 0.000, F 0.683)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.704] [G acc: 0.000]\n",
      "20 [D loss: (0.341)(R 0.000, F 0.682)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.705] [G acc: 0.000]\n",
      "21 [D loss: (0.341)(R 0.000, F 0.682)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.706] [G acc: 0.000]\n",
      "22 [D loss: (0.340)(R 0.000, F 0.681)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.706] [G acc: 0.000]\n",
      "23 [D loss: (0.340)(R 0.000, F 0.680)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.707] [G acc: 0.000]\n",
      "24 [D loss: (0.340)(R 0.000, F 0.679)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.708] [G acc: 0.000]\n",
      "25 [D loss: (0.339)(R 0.000, F 0.679)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.709] [G acc: 0.000]\n",
      "26 [D loss: (0.339)(R 0.000, F 0.678)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.710] [G acc: 0.000]\n",
      "27 [D loss: (0.338)(R 0.000, F 0.677)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.711] [G acc: 0.000]\n",
      "28 [D loss: (0.338)(R 0.000, F 0.676)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.712] [G acc: 0.000]\n",
      "29 [D loss: (0.337)(R 0.000, F 0.674)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.714] [G acc: 0.000]\n",
      "30 [D loss: (0.336)(R 0.000, F 0.673)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.715] [G acc: 0.000]\n",
      "31 [D loss: (0.336)(R 0.000, F 0.671)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.717] [G acc: 0.000]\n",
      "32 [D loss: (0.335)(R 0.000, F 0.670)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.719] [G acc: 0.000]\n",
      "33 [D loss: (0.334)(R 0.000, F 0.667)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.722] [G acc: 0.000]\n",
      "34 [D loss: (0.332)(R 0.000, F 0.665)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.726] [G acc: 0.000]\n",
      "35 [D loss: (0.331)(R 0.000, F 0.662)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.730] [G acc: 0.000]\n",
      "36 [D loss: (0.329)(R 0.000, F 0.658)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.735] [G acc: 0.000]\n",
      "37 [D loss: (0.326)(R 0.000, F 0.652)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.740] [G acc: 0.000]\n",
      "38 [D loss: (0.324)(R 0.001, F 0.648)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.756] [G acc: 0.000]\n",
      "39 [D loss: (0.317)(R 0.000, F 0.634)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.799] [G acc: 0.000]\n",
      "40 [D loss: (0.302)(R 0.000, F 0.604)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.045] [G acc: 0.000]\n",
      "41 [D loss: (7.881)(R 14.668, F 1.095)] [D acc: (0.000)(0.000, 0.000)] [G loss: 0.760] [G acc: 0.000]\n",
      "42 [D loss: (0.314)(R 0.000, F 0.628)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.761] [G acc: 0.000]\n",
      "43 [D loss: (0.312)(R 0.000, F 0.623)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.762] [G acc: 0.000]\n",
      "44 [D loss: (0.309)(R 0.000, F 0.617)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.767] [G acc: 0.000]\n",
      "45 [D loss: (0.307)(R 0.000, F 0.615)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.776] [G acc: 0.000]\n",
      "46 [D loss: (0.306)(R 0.000, F 0.613)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.786] [G acc: 0.000]\n",
      "47 [D loss: (0.304)(R 0.000, F 0.608)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.789] [G acc: 0.000]\n",
      "48 [D loss: (0.300)(R 0.000, F 0.601)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.793] [G acc: 0.000]\n",
      "49 [D loss: (0.298)(R 0.000, F 0.596)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.800] [G acc: 0.000]\n",
      "50 [D loss: (0.295)(R 0.000, F 0.590)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.800] [G acc: 0.000]\n",
      "51 [D loss: (0.292)(R 0.000, F 0.585)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.810] [G acc: 0.000]\n",
      "52 [D loss: (0.288)(R 0.000, F 0.576)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.815] [G acc: 0.000]\n",
      "53 [D loss: (0.288)(R 0.000, F 0.577)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.824] [G acc: 0.000]\n",
      "54 [D loss: (0.282)(R 0.000, F 0.564)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.832] [G acc: 0.000]\n",
      "55 [D loss: (0.278)(R 0.000, F 0.556)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.841] [G acc: 0.000]\n",
      "56 [D loss: (0.279)(R 0.000, F 0.557)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.863] [G acc: 0.000]\n",
      "57 [D loss: (0.271)(R 0.000, F 0.541)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.877] [G acc: 0.000]\n",
      "58 [D loss: (0.262)(R 0.000, F 0.523)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.890] [G acc: 0.000]\n",
      "59 [D loss: (0.255)(R 0.000, F 0.509)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.940] [G acc: 0.000]\n",
      "60 [D loss: (0.249)(R 0.000, F 0.498)] [D acc: (1.000)(1.000, 1.000)] [G loss: 0.961] [G acc: 0.000]\n",
      "61 [D loss: (0.230)(R 0.000, F 0.460)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.027] [G acc: 0.000]\n",
      "62 [D loss: (0.221)(R 0.000, F 0.442)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.081] [G acc: 0.000]\n",
      "63 [D loss: (0.198)(R 0.000, F 0.397)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.203] [G acc: 0.000]\n",
      "64 [D loss: (0.179)(R 0.000, F 0.359)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.391] [G acc: 0.000]\n",
      "65 [D loss: (0.127)(R 0.000, F 0.254)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.798] [G acc: 0.000]\n",
      "66 [D loss: (2.183)(R 3.087, F 1.280)] [D acc: (0.734)(0.789, 0.680)] [G loss: 1.110] [G acc: 0.000]\n",
      "67 [D loss: (0.220)(R 0.000, F 0.441)] [D acc: (0.996)(1.000, 0.992)] [G loss: 1.098] [G acc: 0.000]\n",
      "68 [D loss: (0.203)(R 0.000, F 0.406)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.124] [G acc: 0.000]\n",
      "69 [D loss: (0.197)(R 0.000, F 0.393)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.155] [G acc: 0.000]\n",
      "70 [D loss: (0.188)(R 0.000, F 0.376)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.202] [G acc: 0.000]\n",
      "71 [D loss: (0.179)(R 0.000, F 0.358)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.241] [G acc: 0.000]\n",
      "72 [D loss: (0.168)(R 0.000, F 0.336)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.275] [G acc: 0.000]\n",
      "73 [D loss: (0.159)(R 0.000, F 0.318)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.316] [G acc: 0.000]\n",
      "74 [D loss: (0.147)(R 0.000, F 0.293)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.310] [G acc: 0.000]\n",
      "75 [D loss: (0.136)(R 0.000, F 0.272)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.361] [G acc: 0.000]\n",
      "76 [D loss: (0.118)(R 0.000, F 0.236)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.380] [G acc: 0.000]\n",
      "77 [D loss: (0.104)(R 0.000, F 0.208)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.330] [G acc: 0.000]\n",
      "78 [D loss: (0.087)(R 0.000, F 0.174)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.439] [G acc: 0.000]\n",
      "79 [D loss: (0.067)(R 0.000, F 0.135)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.599] [G acc: 0.000]\n",
      "80 [D loss: (0.052)(R 0.000, F 0.105)] [D acc: (1.000)(1.000, 1.000)] [G loss: 1.904] [G acc: 0.000]\n",
      "81 [D loss: (0.038)(R 0.000, F 0.076)] [D acc: (1.000)(1.000, 1.000)] [G loss: 2.367] [G acc: 0.000]\n",
      "82 [D loss: (0.025)(R 0.000, F 0.051)] [D acc: (1.000)(1.000, 1.000)] [G loss: 2.905] [G acc: 0.000]\n",
      "83 [D loss: (0.018)(R 0.000, F 0.036)] [D acc: (1.000)(1.000, 1.000)] [G loss: 3.651] [G acc: 0.000]\n",
      "84 [D loss: (0.011)(R 0.000, F 0.022)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.259] [G acc: 0.000]\n",
      "85 [D loss: (0.007)(R 0.000, F 0.014)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.035] [G acc: 0.000]\n",
      "86 [D loss: (0.005)(R 0.000, F 0.009)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.915] [G acc: 0.000]\n",
      "87 [D loss: (0.002)(R 0.000, F 0.004)] [D acc: (1.000)(1.000, 1.000)] [G loss: 6.115] [G acc: 0.000]\n",
      "88 [D loss: (3.767)(R 0.726, F 6.808)] [D acc: (0.477)(0.953, 0.000)] [G loss: 3.234] [G acc: 0.000]\n",
      "89 [D loss: (0.021)(R 0.000, F 0.043)] [D acc: (1.000)(1.000, 1.000)] [G loss: 3.271] [G acc: 0.000]\n",
      "90 [D loss: (0.020)(R 0.000, F 0.040)] [D acc: (1.000)(1.000, 1.000)] [G loss: 3.367] [G acc: 0.000]\n",
      "91 [D loss: (0.017)(R 0.000, F 0.034)] [D acc: (1.000)(1.000, 1.000)] [G loss: 3.641] [G acc: 0.000]\n",
      "92 [D loss: (0.014)(R 0.000, F 0.027)] [D acc: (1.000)(1.000, 1.000)] [G loss: 3.808] [G acc: 0.000]\n",
      "93 [D loss: (0.011)(R 0.000, F 0.022)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.142] [G acc: 0.000]\n",
      "94 [D loss: (0.008)(R 0.000, F 0.015)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.347] [G acc: 0.000]\n",
      "95 [D loss: (0.007)(R 0.000, F 0.013)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.549] [G acc: 0.000]\n",
      "96 [D loss: (0.006)(R 0.000, F 0.013)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.728] [G acc: 0.000]\n",
      "97 [D loss: (0.005)(R 0.000, F 0.010)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.033] [G acc: 0.000]\n",
      "98 [D loss: (0.004)(R 0.000, F 0.008)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.061] [G acc: 0.000]\n",
      "99 [D loss: (0.003)(R 0.000, F 0.006)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.382] [G acc: 0.000]\n",
      "100 [D loss: (0.002)(R 0.000, F 0.004)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.614] [G acc: 0.000]\n",
      "101 [D loss: (0.002)(R 0.000, F 0.003)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.761] [G acc: 0.000]\n",
      "102 [D loss: (0.002)(R 0.000, F 0.003)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.855] [G acc: 0.000]\n",
      "103 [D loss: (0.002)(R 0.000, F 0.003)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.854] [G acc: 0.000]\n",
      "104 [D loss: (0.002)(R 0.000, F 0.003)] [D acc: (1.000)(1.000, 1.000)] [G loss: 6.013] [G acc: 0.000]\n",
      "105 [D loss: (0.001)(R 0.000, F 0.003)] [D acc: (1.000)(1.000, 1.000)] [G loss: 6.246] [G acc: 0.000]\n",
      "106 [D loss: (0.001)(R 0.000, F 0.001)] [D acc: (1.000)(1.000, 1.000)] [G loss: 6.554] [G acc: 0.000]\n",
      "107 [D loss: (0.001)(R 0.000, F 0.002)] [D acc: (1.000)(1.000, 1.000)] [G loss: 6.635] [G acc: 0.000]\n",
      "108 [D loss: (0.001)(R 0.000, F 0.002)] [D acc: (1.000)(1.000, 1.000)] [G loss: 6.718] [G acc: 0.000]\n",
      "109 [D loss: (0.001)(R 0.000, F 0.001)] [D acc: (1.000)(1.000, 1.000)] [G loss: 6.805] [G acc: 0.000]\n",
      "110 [D loss: (0.000)(R 0.000, F 0.001)] [D acc: (1.000)(1.000, 1.000)] [G loss: 7.176] [G acc: 0.000]\n",
      "111 [D loss: (0.000)(R 0.000, F 0.001)] [D acc: (1.000)(1.000, 1.000)] [G loss: 7.383] [G acc: 0.000]\n",
      "112 [D loss: (0.000)(R 0.000, F 0.001)] [D acc: (1.000)(1.000, 1.000)] [G loss: 7.388] [G acc: 0.000]\n",
      "113 [D loss: (0.000)(R 0.000, F 0.001)] [D acc: (1.000)(1.000, 1.000)] [G loss: 7.524] [G acc: 0.000]\n",
      "114 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 7.962] [G acc: 0.000]\n",
      "115 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 8.285] [G acc: 0.000]\n",
      "116 [D loss: (0.063)(R 0.126, F 0.000)] [D acc: (0.996)(0.992, 1.000)] [G loss: 7.844] [G acc: 0.000]\n",
      "117 [D loss: (0.000)(R 0.000, F 0.001)] [D acc: (1.000)(1.000, 1.000)] [G loss: 7.775] [G acc: 0.000]\n",
      "118 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 8.001] [G acc: 0.000]\n",
      "119 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 8.325] [G acc: 0.000]\n",
      "120 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 8.507] [G acc: 0.000]\n",
      "121 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 8.744] [G acc: 0.000]\n",
      "122 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 9.067] [G acc: 0.000]\n",
      "123 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 9.327] [G acc: 0.000]\n",
      "124 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 9.279] [G acc: 0.000]\n",
      "125 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 9.471] [G acc: 0.000]\n",
      "126 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 9.691] [G acc: 0.000]\n",
      "127 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 9.868] [G acc: 0.000]\n",
      "128 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 9.954] [G acc: 0.000]\n",
      "129 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 10.228] [G acc: 0.000]\n",
      "130 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 10.408] [G acc: 0.000]\n",
      "131 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 10.693] [G acc: 0.000]\n",
      "132 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 10.592] [G acc: 0.000]\n",
      "133 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 10.690] [G acc: 0.000]\n",
      "134 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 10.872] [G acc: 0.000]\n",
      "135 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 10.976] [G acc: 0.000]\n",
      "136 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.558] [G acc: 0.000]\n",
      "137 [D loss: (0.063)(R 0.126, F 0.000)] [D acc: (0.996)(0.992, 1.000)] [G loss: 11.329] [G acc: 0.000]\n",
      "138 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.489] [G acc: 0.000]\n",
      "139 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.744] [G acc: 0.000]\n",
      "140 [D loss: (0.126)(R 0.252, F 0.000)] [D acc: (0.992)(0.984, 1.000)] [G loss: 11.789] [G acc: 0.000]\n",
      "141 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 12.016] [G acc: 0.000]\n",
      "142 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.503] [G acc: 0.000]\n",
      "143 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.725] [G acc: 0.000]\n",
      "144 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.724] [G acc: 0.000]\n",
      "145 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.936] [G acc: 0.000]\n",
      "146 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 12.278] [G acc: 0.000]\n",
      "147 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 12.312] [G acc: 0.000]\n",
      "148 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 12.471] [G acc: 0.000]\n",
      "149 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 12.408] [G acc: 0.000]\n",
      "150 [D loss: (1.399)(R 0.077, F 2.721)] [D acc: (0.496)(0.992, 0.000)] [G loss: 5.286] [G acc: 0.000]\n",
      "151 [D loss: (0.003)(R 0.000, F 0.005)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.888] [G acc: 0.000]\n",
      "152 [D loss: (0.001)(R 0.000, F 0.002)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.718] [G acc: 0.000]\n",
      "153 [D loss: (0.001)(R 0.000, F 0.003)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.624] [G acc: 0.000]\n",
      "154 [D loss: (0.001)(R 0.000, F 0.001)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.422] [G acc: 0.000]\n",
      "155 [D loss: (0.001)(R 0.000, F 0.002)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.441] [G acc: 0.000]\n",
      "156 [D loss: (0.000)(R 0.000, F 0.001)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.325] [G acc: 0.000]\n",
      "157 [D loss: (0.001)(R 0.000, F 0.002)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.600] [G acc: 0.000]\n",
      "158 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 4.724] [G acc: 0.000]\n",
      "159 [D loss: (0.001)(R 0.000, F 0.003)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.545] [G acc: 0.000]\n",
      "160 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 5.720] [G acc: 0.000]\n",
      "161 [D loss: (0.001)(R 0.000, F 0.001)] [D acc: (1.000)(1.000, 1.000)] [G loss: 6.801] [G acc: 0.000]\n",
      "162 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 7.091] [G acc: 0.000]\n",
      "163 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 7.497] [G acc: 0.000]\n",
      "164 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 7.754] [G acc: 0.000]\n",
      "165 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 8.279] [G acc: 0.000]\n",
      "166 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 8.439] [G acc: 0.000]\n",
      "167 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 8.901] [G acc: 0.000]\n",
      "168 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 9.205] [G acc: 0.000]\n",
      "169 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 9.736] [G acc: 0.000]\n",
      "170 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 10.026] [G acc: 0.000]\n",
      "171 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 10.554] [G acc: 0.000]\n",
      "172 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 10.643] [G acc: 0.000]\n",
      "173 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.000] [G acc: 0.000]\n",
      "174 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.063] [G acc: 0.000]\n",
      "175 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.447] [G acc: 0.000]\n",
      "176 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.680] [G acc: 0.000]\n",
      "177 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 11.757] [G acc: 0.000]\n",
      "178 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 12.144] [G acc: 0.000]\n",
      "179 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 12.455] [G acc: 0.000]\n",
      "180 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 12.854] [G acc: 0.000]\n",
      "181 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 12.871] [G acc: 0.000]\n",
      "182 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 12.991] [G acc: 0.000]\n",
      "183 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 13.073] [G acc: 0.000]\n",
      "184 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 13.245] [G acc: 0.000]\n",
      "185 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 13.477] [G acc: 0.000]\n",
      "186 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 13.702] [G acc: 0.000]\n",
      "187 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 13.711] [G acc: 0.000]\n",
      "188 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 13.878] [G acc: 0.000]\n",
      "189 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.094] [G acc: 0.000]\n",
      "190 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.088] [G acc: 0.000]\n",
      "191 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.140] [G acc: 0.000]\n",
      "192 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.481] [G acc: 0.000]\n",
      "193 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.705] [G acc: 0.000]\n",
      "194 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.703] [G acc: 0.000]\n",
      "195 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.799] [G acc: 0.000]\n",
      "196 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.796] [G acc: 0.000]\n",
      "197 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.939] [G acc: 0.000]\n",
      "198 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.109] [G acc: 0.000]\n",
      "199 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.163] [G acc: 0.000]\n",
      "200 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.178] [G acc: 0.000]\n",
      "201 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.726] [G acc: 0.000]\n",
      "202 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.534] [G acc: 0.000]\n",
      "203 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.863] [G acc: 0.000]\n",
      "204 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 14.980] [G acc: 0.000]\n",
      "205 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.098] [G acc: 0.000]\n",
      "206 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.362] [G acc: 0.000]\n",
      "207 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.265] [G acc: 0.000]\n",
      "208 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.417] [G acc: 0.000]\n",
      "209 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.337] [G acc: 0.000]\n",
      "210 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.697] [G acc: 0.000]\n",
      "211 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.596] [G acc: 0.000]\n",
      "212 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.752] [G acc: 0.000]\n",
      "213 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.881] [G acc: 0.000]\n",
      "214 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.820] [G acc: 0.000]\n",
      "215 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.823] [G acc: 0.000]\n",
      "216 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.834] [G acc: 0.000]\n",
      "217 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.986] [G acc: 0.000]\n",
      "218 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.893] [G acc: 0.000]\n",
      "219 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.923] [G acc: 0.000]\n",
      "220 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.897] [G acc: 0.000]\n",
      "221 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.788] [G acc: 0.000]\n",
      "222 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.949] [G acc: 0.000]\n",
      "223 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.931] [G acc: 0.000]\n",
      "224 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.974] [G acc: 0.000]\n",
      "225 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.020] [G acc: 0.000]\n",
      "226 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.944] [G acc: 0.000]\n",
      "227 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.986] [G acc: 0.000]\n",
      "228 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.953] [G acc: 0.000]\n",
      "229 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.055] [G acc: 0.000]\n",
      "230 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.053] [G acc: 0.000]\n",
      "231 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.971] [G acc: 0.000]\n",
      "232 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.925] [G acc: 0.000]\n",
      "233 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.962] [G acc: 0.000]\n",
      "234 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.960] [G acc: 0.000]\n",
      "235 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.036] [G acc: 0.000]\n",
      "236 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.983] [G acc: 0.000]\n",
      "237 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 15.985] [G acc: 0.000]\n",
      "238 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.065] [G acc: 0.000]\n",
      "239 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.016] [G acc: 0.000]\n",
      "240 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.071] [G acc: 0.000]\n",
      "241 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.090] [G acc: 0.000]\n",
      "242 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.078] [G acc: 0.000]\n",
      "243 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.073] [G acc: 0.000]\n",
      "244 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.061] [G acc: 0.000]\n",
      "245 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.073] [G acc: 0.000]\n",
      "246 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.048] [G acc: 0.000]\n",
      "247 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.044] [G acc: 0.000]\n",
      "248 [D loss: (0.315)(R 0.009, F 0.620)] [D acc: (0.789)(0.992, 0.586)] [G loss: 16.118] [G acc: 0.000]\n",
      "249 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "250 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "251 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "252 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "253 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "254 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "255 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "256 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "257 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "258 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "259 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "260 [D loss: (8.059)(R 16.118, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "261 [D loss: (8.038)(R 16.077, F 0.000)] [D acc: (0.500)(0.000, 1.000)] [G loss: 16.117] [G acc: 0.000]\n",
      "262 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "263 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.117] [G acc: 0.000]\n",
      "264 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "265 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.118] [G acc: 0.000]\n",
      "266 [D loss: (0.000)(R 0.000, F 0.000)] [D acc: (1.000)(1.000, 1.000)] [G loss: 16.117] [G acc: 0.000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5afd8fbebb90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRUN_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRINT_EVERY_N_BATCHES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/bram/Data/programming/onlineCourses/generative/models/GAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batches, using_generator)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musing_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/bram/Data/programming/onlineCourses/generative/models/GAN.py\u001b[0m in \u001b[0;36mtrain_generator\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/generative/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/generative/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/generative/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(x_train,BATCH_SIZE,EPOCHS,RUN_FOLDER, PRINT_EVERY_N_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[0] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "\n",
    "plt.plot([x[1] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[2] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[0] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x[3] for x in gan.d_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x[4] for x in gan.d_losses], color='green', linewidth=0.25)\n",
    "plt.plot([x[5] for x in gan.d_losses], color='red', linewidth=0.25)\n",
    "plt.plot([x[1] for x in gan.g_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('accuracy', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.sample_images(RUN_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
